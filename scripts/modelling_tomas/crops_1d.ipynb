{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crops import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([569, 64, 64])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_domains = np.loadtxt('../../data/our_input/train_domains.csv', dtype='O')\n",
    "\n",
    "#X = torch.load(f'../../data/our_input/tensors/{train_domains[0]}_X.pt')\n",
    "#Y = torch.load(f'../../data/our_input/Y_tensors/{train_domains[0]}_Y.pt')\n",
    "\n",
    "X = torch.load(f'../../data/our_input/tensors/4nb5B02_X.pt')\n",
    "Y = torch.load(f'../../data/our_input/Y_tensors/4nb5B02_Y.pt')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_1d(input_1d, crop_size=64, random_state=1):\n",
    "    \"\"\"\n",
    "    Pads 1D input\n",
    "    \n",
    "    Input:\n",
    "        input_1d    : 1D torch tensor\n",
    "        random_state: int\n",
    "        \n",
    "    Output:\n",
    "        padded1D: list of tuples of padded 1D (i, j) inputs for each crop \n",
    "    \"\"\"\n",
    "    L = len(input_1d)\n",
    "    crop_indices = make_crop_indices(L, random_state=random_state)\n",
    "    padded = []\n",
    "    \n",
    "    if L < 64:\n",
    "        np.random.seed(random_state)\n",
    "        offset_range = np.arange(crop_size - L + 1)\n",
    "        i_offset, j_offset = np.random.choice(offset_range), np.random.choice(offset_range)\n",
    "        \n",
    "        cropped_i = torch.cat((\n",
    "            torch.zeros(i_offset, dtype=torch.long),\n",
    "            input_1d.to(torch.long),\n",
    "            torch.zeros(crop_size - L - i_offset, dtype=torch.long)\n",
    "        ))\n",
    "        \n",
    "        cropped_j = torch.cat((\n",
    "            torch.zeros(j_offset, dtype=torch.long),\n",
    "            input_1d.to(torch.long),\n",
    "            torch.zeros(crop_size - L - j_offset, dtype=torch.long)\n",
    "        ))\n",
    "        padded.append((cropped_i.view(1, 64), cropped_j.view(1, 64)))\n",
    "    else:\n",
    "        for ci in crop_indices:\n",
    "            i0, imax = ci[0][0], ci[1][0]\n",
    "            j0, jmax = ci[0][1], ci[1][1]\n",
    "            padding = ci[2]\n",
    "            \n",
    "            # crop\n",
    "            cropped_i, cropped_j = input_1d[i0:imax], input_1d[j0:jmax]\n",
    "            \n",
    "            # pad\n",
    "            \n",
    "            i_padding, j_padding = crop_size - (imax - i0), crop_size - (jmax - j0)\n",
    "            \n",
    "            if padding == 'topleft':\n",
    "                # pad both from left\n",
    "                cropped_i = torch.cat((torch.zeros(i_padding, dtype=torch.long), cropped_i.to(torch.long)))\n",
    "                cropped_j = torch.cat((torch.zeros(j_padding, dtype=torch.long), cropped_j.to(torch.long)))\n",
    "                \n",
    "            elif padding == 'top':\n",
    "                # pad only i from left\n",
    "                cropped_i = torch.cat((torch.zeros(i_padding, dtype=torch.long), cropped_i.to(torch.long)))\n",
    "                cropped_j = cropped_j.to(torch.long)\n",
    "            elif padding == 'topright':\n",
    "                # pad both i from left and j from right\n",
    "                cropped_i = torch.cat((torch.zeros(i_padding, dtype=torch.long), cropped_i.to(torch.long)))\n",
    "                cropped_j = torch.cat((cropped_j.to(torch.long), torch.zeros(j_padding, dtype=torch.long)))\n",
    "                \n",
    "            elif padding == 'left':\n",
    "                # pad only j from left\n",
    "                cropped_i = cropped_i.to(torch.long)\n",
    "                cropped_j = torch.cat((torch.zeros(j_padding, dtype=torch.long), cropped_j.to(torch.long)))\n",
    "                \n",
    "            elif padding is None:\n",
    "                cropped_i = cropped_i.to(torch.long)\n",
    "                cropped_j = cropped_j.to(torch.long)\n",
    "            \n",
    "            elif padding == 'right':\n",
    "                # pad only j from right\n",
    "                cropped_i = cropped_i.to(torch.long)\n",
    "                cropped_j = torch.cat((cropped_j.to(torch.long), torch.zeros(j_padding, dtype=torch.long)))\n",
    "                \n",
    "            elif padding == 'bottomleft':\n",
    "                # i from right and j from left\n",
    "                cropped_i = torch.cat((cropped_i.to(torch.long), torch.zeros(i_padding, dtype=torch.long)))\n",
    "                cropped_j = torch.cat((torch.zeros(j_padding, dtype=torch.long), cropped_j.to(torch.long)))\n",
    "                \n",
    "            elif padding == 'bottom':\n",
    "                # pad only i from right\n",
    "                cropped_i = torch.cat((cropped_i.to(torch.long), torch.zeros(i_padding, dtype=torch.long)))\n",
    "                cropped_j = cropped_j.to(torch.long)\n",
    "            elif padding == 'bottomright':\n",
    "                # pad both from right\n",
    "                cropped_i = torch.cat((cropped_i.to(torch.long), torch.zeros(i_padding, dtype=torch.long)))\n",
    "                cropped_j = torch.cat((cropped_j.to(torch.long), torch.zeros(j_padding, dtype=torch.long)))\n",
    "                \n",
    "            padded.append((cropped_i.view(1, 64), cropped_j.view(1, 64)))\n",
    "    return padded   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_batches(X, Y, c=64, random_state=1):\n",
    "    \"\"\"Function should return input and output of shapes:\n",
    "    input:  (crops, 675, 64, 64)\n",
    "    output: (crops, 64, 64)\n",
    "    \"\"\"\n",
    "    d_map, secondary, phi, psi = Y\n",
    "    \n",
    "    Ch, L = X.shape[0], X.shape[1]\n",
    "    d_map = d_map.reshape((1, L, L))\n",
    "    \n",
    "    padded_sec = pad_1d(secondary, random_state=random_state)\n",
    "    padded_phi = pad_1d(psi, random_state=random_state)\n",
    "    padded_psi = pad_1d(psi, random_state=random_state)\n",
    "    \n",
    "    if L < c:\n",
    "        output_batches = np.empty((1, c + 6, c))\n",
    "        \n",
    "        input_batches, output_batches0 = pad_crop(X, 'all', d_map, random_state=random_state)\n",
    "               \n",
    "        # add auxiliary losses to the output\n",
    "        output_batches[:, :64, :] = output_batches0\n",
    "        output_batches[:, 64:, :] = torch.cat((padded_sec[0][0], padded_sec[0][1], \n",
    "                              padded_phi[0][0], padded_phi[0][1],\n",
    "                              padded_psi[0][0], padded_psi[0][1]\n",
    "                             ))\n",
    "        \n",
    "        return torch.from_numpy(input_batches).to(torch.float32), torch.from_numpy(output_batches).to(torch.long)\n",
    "    \n",
    "    else:\n",
    "        crop_indices = make_crop_indices(L, c=c, random_state=random_state)\n",
    "\n",
    "        input_batches = np.empty((len(crop_indices), Ch, c, c))\n",
    "        output_batches = np.empty((len(crop_indices), c + 6, c))\n",
    "\n",
    "        for m in range(len(crop_indices)):\n",
    "            (i0, j0), (i, j), padding = crop_indices[m]\n",
    "            input_batches[m, :, :, :] = pad_crop(X[:, i0:i, j0:j], padding, c)\n",
    "            output_batches[m, :64, :] = pad_crop(d_map[:, i0:i, j0:j], padding, c)\n",
    "            \n",
    "            # add auxiliary losses to the output \n",
    "            output_batches[m, 64:, :] = torch.cat((\n",
    "                padded_sec[m][0], padded_sec[m][1], \n",
    "                padded_phi[m][0], padded_phi[m][1],\n",
    "                padded_psi[m][0], padded_psi[m][1]\n",
    "            ))      \n",
    "        \n",
    "        return torch.from_numpy(input_batches).to(torch.float32), torch.from_numpy(output_batches).to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_map, secondary, phi, psi = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, o = _make_batches(X, Y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 23, 15, 16, 14,\n",
       "        15, 14, 15, 15, 15, 15, 14, 14, 14, 15, 14, 15, 15, 15, 15, 15, 15, 15,\n",
       "        14, 15, 15, 15, 16, 20, 15, 20, 35, 33])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0, 69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 23, 15, 16, 14,\n",
       "         15, 14, 15, 15, 15, 15, 14, 14, 14, 15, 14, 15, 15, 15, 15, 15, 15, 15,\n",
       "         14, 15, 15, 15, 16, 20, 15, 20, 35, 33]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0, 69:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-172-515c50a32455>\u001b[0m(21)\u001b[0;36m_make_batches\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     19 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     20 \u001b[0;31m        \u001b[0;31m# add auxiliary losses to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 21 \u001b[0;31m        padded_Y = torch.cat((torch.from_numpy(output_batches).to(torch.long),\n",
      "\u001b[0m\u001b[0;32m     22 \u001b[0;31m                              \u001b[0mpadded_sec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_sec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     23 \u001b[0;31m                              \u001b[0mpadded_phi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_phi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  padded_sec[0][0].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 64])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "        [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "        [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0,  ..., 20, 35, 33],\n",
       "        [ 0,  0,  0,  ..., 20, 35, 33],\n",
       "        [ 0,  0,  0,  ..., 20, 35, 33]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([569, 136, 136])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pad_1d(secondary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((s[0][0], s[0][1])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[(0, 0), (33, 32), 'topleft'],\n",
       "       [(0, 32), (33, 96), 'top'],\n",
       "       [(0, 96), (33, 130), 'topright'],\n",
       "       [(33, 0), (97, 32), 'left'],\n",
       "       [(33, 32), (97, 96), None],\n",
       "       [(33, 96), (97, 130), 'right'],\n",
       "       [(97, 0), (130, 32), 'bottomleft'],\n",
       "       [(97, 32), (130, 96), 'bottom'],\n",
       "       [(97, 96), (130, 130), 'bottomright']], dtype=object)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_crop_indices(130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, o = make_batches(X, d_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "        [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "        [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0,  ..., 14, 16, 10],\n",
       "        [ 0,  0,  0,  ..., 10, 14, 11],\n",
       "        [ 0,  0,  0,  ...,  7,  6,  5]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "        [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "        [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0,  ..., 10, 14, 11],\n",
       "        [ 0,  0,  0,  ...,  7,  6,  5],\n",
       "        [ 0,  0,  0,  ...,  1,  1,  8]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((o[0], s[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f97ec2ebe9db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "s[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 8, 8, 8, 4, 4, 4, 8, 7, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        6, 6, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((torch.zeros(8, dtype=torch.long), aa.to(torch.long)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
